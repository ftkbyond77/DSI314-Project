import os
from dotenv import load_dotenv
from pinecone import Pinecone
from collections import defaultdict

# ------------------------------------------------
# 1. ‡πÇ‡∏´‡∏•‡∏î .env ‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å 1 ‡∏ä‡∏±‡πâ‡∏ô
# ------------------------------------------------
env_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(dotenv_path=env_path)

api_key = os.getenv("PINECONE_API_KEY")
index_name = os.getenv("PINECONE_INDEX_NAME")

if not api_key or not index_name:
    raise ValueError("‚ùå Missing PINECONE_API_KEY or PINECONE_INDEX_NAME in .env file")

# ------------------------------------------------
# 2. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Pinecone
# ------------------------------------------------
pc = Pinecone(api_key=api_key)
index = pc.Index(index_name)

# ------------------------------------------------
# 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏ô‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ------------------------------------------------
file_chunk_count = defaultdict(int)     # ‡∏ô‡∏±‡∏ö chunk ‡∏ï‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
upload_to_files = defaultdict(set)      # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° upload_id ‚Üí set of files

def normalize_metadata(meta):
    """
    ‡πÅ‡∏õ‡∏•‡∏á metadata ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô schema ‡∏Å‡∏•‡∏≤‡∏á:
    - category = upload_id
    - doc_name = file (‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö)
    """
    doc_name = "unknown"
    category = "unknown"

    if isinstance(meta, dict):
        # 1. upload_id
        category = str(meta.get("upload_id", "unknown")).strip()

        # 2. file
        raw_file = None
        if "file" in meta and meta["file"]:
            raw_file = meta["file"]
        elif "metadata" in meta and isinstance(meta["metadata"], dict):
            raw_file = meta["metadata"].get("file")

        if raw_file:
            # strip space/newline ‡πÅ‡∏•‡∏∞ convert ‡πÄ‡∏õ‡πá‡∏ô string
            doc_name = str(raw_file).strip().replace("\n", "").replace("\r", "")
    
    return category, doc_name

# ------------------------------------------------
# 4. ‡πÇ‡∏´‡∏•‡∏î vectors ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Pinecone
# ------------------------------------------------
print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î vectors ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Pinecone...")

total_vectors = 0
for batch in index.list():
    for vector in batch:
        meta = vector.get("metadata", {}) if isinstance(vector, dict) else {}
        category, doc_name = normalize_metadata(meta)

        file_chunk_count[doc_name] += 1
        upload_to_files[category].add(doc_name)

print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_vectors:,} vectors ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\n")

# ------------------------------------------------
# 5. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏ß‡∏° chunks ‡∏ï‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
# ------------------------------------------------
print("üìò ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunk ‡∏ï‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£:\n")
for file_name, c in sorted(file_chunk_count.items(), key=lambda x: x[1], reverse=True):
    print(f"{file_name:<40} {c:>5} chunks")

# ------------------------------------------------
# 6. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏ï‡∏≤‡∏° upload_id (‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà)
# ------------------------------------------------
print("\nüìÇ ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏° upload_id:\n")
for upload_id, files in upload_to_files.items():
    total_chunks = sum(file_chunk_count[f] for f in files)
    print(f"Upload ID: {upload_id}")
    print(f"  - ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(files)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"  - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks ‡∏£‡∏ß‡∏°: {total_chunks}\n")

# ------------------------------------------------
# 7. Return summary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏≠‡∏∑‡πà‡∏ô
# ------------------------------------------------
summary = {
    "by_file": dict(file_chunk_count),
    "by_upload": {
        upload_id: {
            "file_count": len(files),
            "chunk_count": sum(file_chunk_count[f] for f in files),
        }
        for upload_id, files in upload_to_files.items()
    },
}

if __name__ == "__main__":
    print("‚úÖ Summary dictionary ready for further use")
